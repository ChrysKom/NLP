{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKOGrDbftgp0"
      },
      "source": [
        "# RAG-Powered Assistant for Custom Cash Register Manual\n",
        "\n",
        "This project demonstrates a simple Retrieval-Augmented Generation (RAG) pipeline using a custom PDF manual I created for a point-of-sale (POS) cash register system. The goal is to allow users to ask natural language questions (e.g., *\"How do I print a daily report?\"*) and get accurate, concise answers based on the manual's content. It's a practical showcase of how LLMs can enhance user guidance for specialized tools, built entirely with free and open-source tools.\n",
        "\n",
        "Chrysovalantis K."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LitdtH2T8nq4"
      },
      "source": [
        "#Pips And Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FEpFuFCxw9wd",
        "outputId": "31c494e8-8f94-45fc-ed7e-4cd5ac918cf6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Collecting sentence-transformers\n",
            "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Collecting PyMuPDF\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
            "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.7/345.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDF, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, faiss-cpu, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, sentence-transformers\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: sentence-transformers\n",
            "    Found existing installation: sentence-transformers 3.4.1\n",
            "    Uninstalling sentence-transformers-3.4.1:\n",
            "      Successfully uninstalled sentence-transformers-3.4.1\n",
            "Successfully installed PyMuPDF-1.25.5 faiss-cpu-1.11.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 sentence-transformers-4.1.0\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U sentence-transformers faiss-cpu PyMuPDF\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kB4-zgVc8VO4"
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF\n",
        "from typing import List\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import numpy as np\n",
        "import faiss\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HoFt6OVeaBus",
        "outputId": "ac14ecbd-533d-4e80-8c91-efa15e1d5414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting rouge-score\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge-score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rouge-score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge-score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk->rouge-score) (4.67.1)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=bb208198a635e0e94a9b1518fbebd059c30a79e942f65fdc3ac3ffdd28dd4817\n",
            "  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: rouge-score\n",
            "Successfully installed rouge-score-0.1.2\n"
          ]
        }
      ],
      "source": [
        "pip install rouge-score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cNoy1nj113ge",
        "outputId": "de377e0c-7ce8-4b7a-bdc1-f43aa09f2bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "pdf_path = '/content/drive/MyDrive/Custom Manual.pdf'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVuM-4Ua8tGw"
      },
      "source": [
        "CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DN9BOoCXquPC"
      },
      "source": [
        "# PDF Extraction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10Vtn6G8uz74"
      },
      "source": [
        "Extracts all text from a PDF file using PyMuPDF.  \n",
        "Opens the PDF, iterates through each page, and collects the text.  \n",
        "Returns the full document text as a single string."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLQlyx882d8e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    text = \"\"\n",
        "    for page in doc:\n",
        "        text += page.get_text()\n",
        "    return text\n",
        "\n",
        "pdf_text = extract_text_from_pdf(pdf_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDVjeNf9u5ap"
      },
      "source": [
        "# Chunking the Text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGziu5oZraPU"
      },
      "source": [
        "Splits the extracted text into overlapping word chunks to ensure context continuity.  \n",
        "Each chunk has a maximum length of 100 words with a 25-word overlap, I did this based on the setup of my pdf.  \n",
        "This helps improve retrieval accuracy when searching for relevant information later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TS-1aTDc2d5r"
      },
      "outputs": [],
      "source": [
        "def chunk_text(text: str, max_length: int = 100, overlap: int = 25) -> List[str]:\n",
        "    words = text.split()\n",
        "    chunks = []\n",
        "    i = 0\n",
        "    while i < len(words):\n",
        "        chunk = words[i:i + max_length]\n",
        "        chunks.append(\" \".join(chunk))\n",
        "        i += max_length - overlap\n",
        "    return chunks\n",
        "\n",
        "chunks = chunk_text(pdf_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFO1Oc-7vECd"
      },
      "source": [
        "# Embedding and Indexing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVR0UIE6rmMo"
      },
      "source": [
        "Embeds each chunk into a dense vector using the `all-mpnet-base-v2` model.  \n",
        "This model is chosen for its strong performance in English sentence similarity tasks.  \n",
        "FAISS is then used to index these embeddings for fast similarity-based retrieval.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 528,
          "referenced_widgets": [
            "ca3564c8bbf24297b595ee75c68a70fa",
            "e7bdef46ee994b9fb8c0eb28162bbe17",
            "cd6d104717954768a02f41e82a1297a9",
            "5286889e64ec47ac8ae24667ec863828",
            "2e608bef998e46eeaf26f4f890d71d2a",
            "17107c2cfa25412e844c6e8b8ddb0975",
            "46d14ddd4f03450fadc9929ebf1b6d98",
            "fa2982af12a8420d8d3d7d3091fcb4c6",
            "b34f85726a714a718839d9ed164f3346",
            "2357970426054e06a8727dbbb11626a2",
            "d2f8d30d09184c8596a21447d3daada5",
            "deb3861b7a4444bf90f9ba3a834d17b5",
            "2ea9499eb9ea4b2cb4575ca0014b2883",
            "b000b8be38dc42bcb4cb500f284c1af3",
            "1e04ee52127c445dafa9a961c423905f",
            "cd961e52d487446c897a6324d13929c8",
            "c77b60105e9442979034b914a0726dc1",
            "75fe42a771a746868be45a8b228b8893",
            "9e0fc282a5e2488f83e322d21e227fb2",
            "29402ab85d3d4502a7364e2b123abc48",
            "d3a22ccfdd844699aea0e87b0661e95b",
            "f710ad9dcbfc4c28a5dad6b389d91eab",
            "eaa43711f342438ca532c6c526022bf5",
            "5f74434734b64dd49fbd73a1a0cf8c67",
            "292e1abefa4845e98e200a13f211cf82",
            "c887f3a3465a49389ee19325c781deed",
            "73de17a690a640c4ae80956c6d97fa51",
            "9654b0912d474aaaac884f7621233608",
            "38181357c13c4c6388d43051d68c3b89",
            "5e309053ff4a49c091425c0d48b8761b",
            "9ed5010f6d924976adb11513d356bc21",
            "2a71fb365c064a6dbc187946e9fcffed",
            "517f677184c94312b7f3c465a39f04cd",
            "73cb040cdab14f738c4262f9841fa344",
            "3b9bc5c337cd4b84973d376df345dc42",
            "8283fd26a05149b690151cdff5d630f7",
            "97eb2755070a47988debe2652198fb3e",
            "09e0af801ac34d74b1b437db4c3e64f0",
            "adbb4d9baf494a21a4f5ffdf084bffb2",
            "d5c7d9bacdeb42c79eb446817c48aea2",
            "f8da1a5520e64e5c83d2cd23ccffcd5f",
            "b50356f2236448a59090c08fbab1a574",
            "f64793944c4540a3b40a877bf0c0c1b8",
            "6c07cfefddf642ad9c2976d7d9f10959",
            "d2735565fc2746c1b786013dbb484348",
            "69f5d5d49136423097e987ec7a87188c",
            "9625fffab58a4967aa6813759f4ceebd",
            "47f2c868d38a4b9fbce63c3ad6452dad",
            "f2861f8d292b4da5ada5aed20d07eedc",
            "8447a6f11ba64c868b6c8085bb117327",
            "0c6099c773b84167a5b01817083759b4",
            "035dd9c5bb4f44338a1b36b1e26055fc",
            "f59242eebfdf4e85a2d583077d75cd9a",
            "274a10e46a724438acf110db34428d10",
            "7c44af37627747fca3c667c8169c1514",
            "4807b0bae3e441a69e98c73a21989cab",
            "8c8b16a51f1349039a8f3acd455b2e13",
            "d23a75734b5b4475aabc992da448b5d6",
            "bf4bbfc36310474ea489d3a09fd2b848",
            "6b2cc703a7394d819d83014012e1d417",
            "47a3a0b82cd74796922b4656e30461c4",
            "b6d8211d924d4eabbe4366c877637b0a",
            "3291c9d8313b44908e6ba70d54b8f7e4",
            "f0f3df108c29487dad06585c93785d87",
            "aad4c509b2f34f5488a79263ac066fbc",
            "65033876b6ca44df8bfe33a61e1be3c4",
            "68807cf29e6e4a08bd525e59578c351b",
            "f167459428aa4738a7c8bdf739423d88",
            "a35442d885e7407282a05990071e2dce",
            "951da0932b954d05829038256d3c4de3",
            "e4f786f12ae1421793e52182a84b3368",
            "c201f0cb9f22423fa7cb801e5aa1d081",
            "4469fb92d2e04d1583eed2887413cee7",
            "95e761700d8041e1a1e57e3ce6db7436",
            "fa6eccb641a2498ebb0273b2c12c36b8",
            "6f2902b5ea284f5fb4b739e893a2fca7",
            "753af3f725a44546bf3ab0c106456c12",
            "49f180c76a674ccbb785afe8c8353bb1",
            "aeae007db1f04126b08ffa735b91fc0a",
            "fc8ac31747894ad1a6c159f714ca5b9e",
            "180f0f1b0a264b988680aa2740d9a017",
            "f700c43ae4bc4bf6ba2297ebc4b71218",
            "5a101a231131430c98f4d0612996c4c6",
            "3293397bb245432e81cbdc6822ed1411",
            "a6d4f56aea954e22b94080dcd9ad6980",
            "11b6e31c12a24f92b0bca74b37997cb5",
            "f4ed5c8f19f948e7a140aa7be2df4d01",
            "058307a39eb244ec87f926fb7a83918c",
            "d836044f00d8468f94bf76e83f7012b6",
            "0eba8fedaa4c4df59f8ab6d54079f58d",
            "56030f5882134ac48296cd04ac002c7d",
            "37595d76f9c74929b2311860331e7c47",
            "540a1a8d80f34d87ac12d3939678c6ee",
            "e423433d70e248ab8c006c3e25aaee91",
            "81d9152b06db4d4dac42d65cf11d89e0",
            "c3a1434ddc10434ea80d34c7a7ea182f",
            "8730264ff6ad40cd99b21f52e9cfc121",
            "eb16c0b4a86d42fb851e01d704375718",
            "201c1608e6654c78b1fef2b661c88c83",
            "902b63722f2a4e53ac8b2c03f52e1084",
            "90dde38a70d34d07810453db78382d81",
            "b7efa4d82e234fdea171247083e6056d",
            "1a09b0594aa74168852aadaffe14424e",
            "844fbcb84d4f47dfbdc9feff0d609cc0",
            "f12b592ed04944abb7b749c39f7d3e8f",
            "495d52c2ba894e02b3bfb56862a8e2f3",
            "30eac96a3d904276937858a811705bf5",
            "1172669313a1437b8e596ffd498170de",
            "7fd209c42e434198ae6b621c67209fa3",
            "a30f2eab0ffe4815b582f434ba68f94d",
            "80da034e89e24d4e96eee2c27f1d253d",
            "08da8f31104d4948bfe86f006c3025de",
            "462ac1405da94777bbabeae9c7dbea27",
            "aa407d236c88441191cf4848d1109c65",
            "2b312733cd7548b8b0db38fa9d17a639",
            "8193b21ab1544b8d93be06fcfda6f13d",
            "486c850c9ace41fcb9043e5ca9a9050f",
            "16a408c999ce4ecb88d4806df1dacee9",
            "36313a1c5bc447daa9c0906c9712149a",
            "95e2feb843364096a9aaecb72fc4335b",
            "57b5f2b191b544e9b3942fa53d217b1b"
          ]
        },
        "id": "_p1jH9So2z61",
        "outputId": "454291c5-cfe2-4ffd-b50c-733a7e8c7cf2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca3564c8bbf24297b595ee75c68a70fa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "deb3861b7a4444bf90f9ba3a834d17b5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eaa43711f342438ca532c6c526022bf5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/10.4k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "73cb040cdab14f738c4262f9841fa344",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d2735565fc2746c1b786013dbb484348",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4807b0bae3e441a69e98c73a21989cab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "68807cf29e6e4a08bd525e59578c351b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/363 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49f180c76a674ccbb785afe8c8353bb1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d836044f00d8468f94bf76e83f7012b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "902b63722f2a4e53ac8b2c03f52e1084",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "80da034e89e24d4e96eee2c27f1d253d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = SentenceTransformer('all-mpnet-base-v2')\n",
        "\n",
        "embeddings = model.encode(chunks, convert_to_numpy=True)\n",
        "\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)\n",
        "index.add(embeddings)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIZ7939NvWSy"
      },
      "source": [
        "# Retrieving Relevant Chunks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0kqN5dtQsMyM"
      },
      "source": [
        "Encodes the user question into the same vector space as the document chunks.  \n",
        "Retrieves the top-k most similar chunks using FAISS based on vector similarity.  \n",
        "Returns them as context for answering the question.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWzVoMfs24Uk"
      },
      "outputs": [],
      "source": [
        "def retrieve_answer(question, top_k=3):\n",
        "    question_embedding = model.encode([question])\n",
        "    D, I = index.search(np.array(question_embedding), top_k)\n",
        "    retrieved_chunks = [chunks[i] for i in I[0]]\n",
        "    return \"\\n---\\n\".join(retrieved_chunks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVR7XkcKsUxz"
      },
      "source": [
        "Checking how it works.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGFTNCee6k-u",
        "outputId": "08952fae-28d2-45ed-fc04-11634cb87adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "that have been stored. From there the user can add items by selecting the + at the bottom of the screen, edit existing items by selecting the yellow pencil to the right of the stored item or delete them by selecting the red X to the right of the stored item. How to add an item? In the screen \"ADD ITEM\" the name and description of the item is filled in. Then select the department to which the article will fall, the gross sales price and the net profit. The net sales price is automatically filled in based on the\n",
            "---\n",
            "the desired quantity. Then select the X ,enter the price of the product and select the corresponding section. To import an item, you select \"ITEMS\" to display the items stored in the warehouse (See STORAGE section). After selecting the item, you press check. To enter a discount after the products have been entered, you select \"DISCOUNT\" and enter the discount value. To enter a comment, you select \"2nd level\" and then comment. You enter the comment and press check. The \"AC\" button is used to delete all the products that have been entered and the \"C\" button is used to\n",
            "---\n",
            "to be created, then click next to proceed to the next page. How to change contract details? You will then go to the contract details tab. If there is no registered contract then the mandatory fields (those with an asterisk) will need to be entered and the \"Budget\" option will be selected. Clicking OK will display the message \"Contract has been successfully added\". If the contract already exists then the contract details will be displayed and click \"Continue\". To enter a new contract then you will select the \"+\" symbol next to the contract name and will be prompted to\n"
          ]
        }
      ],
      "source": [
        "greek_question = \"How to add an item?\"\n",
        "print(retrieve_answer(greek_question))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I9hky_B3vZ_T"
      },
      "source": [
        "# Question Answering with FLAN-T5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3eGLPPYIssXI"
      },
      "source": [
        "Loads the `Flan-T5 Large` model for text-to-text generation using Hugging Face's pipeline.  \n",
        "This model generates answers based on retrieved context and the user's question.  \n",
        "It's a strong general-purpose LLM fine-tuned for instruction following.\n",
        "\n",
        "Pros: Free to use, high-quality outputs, good for many tasks.  \n",
        "Cons: Limited input size (~512 tokens), can sometimes truncate or miss detail.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 348,
          "referenced_widgets": [
            "a53cc0581da949b19ccea2d9d8c9edca",
            "1f314aa89cd74a9e97bf18a92d36e4cf",
            "9eb845c214ce4515b94eb2669b49f436",
            "97313c65af3e4f1fad63b4014371fff0",
            "489247a9116543128faa507abcd2a77f",
            "af9d83a459ff42d1a6309503578b38fc",
            "5626bfd9847b4a30afd2ebef93343c41",
            "cfbbcfad36cf465e931c2b832f12fd29",
            "5339eb0e8cc34cf0ac0f51d069a60a9b",
            "7329bf1bf9a244e7947030cd0a2a4fd1",
            "00514db2a33e4d3c89b259090356d1ea",
            "501208bb8afc4150a5dad8ce74f56eb5",
            "a925b02bed4d4ac1bd2b2a97f8a24ec6",
            "bc27a190b67f4f059fea0496f4127f08",
            "0a2965b3ebbf44e4a420093429edc02e",
            "cc8722fbf62a44f58d670dd7cd527f77",
            "d2b7e57daafd48058b525cb96d656d95",
            "ddd33681b7724e18b5aa5e9dc912215e",
            "ccb4585480eb4f7b9b9ed7e34ff356cf",
            "6400f83e8c594aa0bed6c756c2181c79",
            "3547c7f585304fffa3857418f69d5f38",
            "a0ee592701804251aabbdf258ca94bbd",
            "b05dfefdde1b4a11a182ae3234819578",
            "6c2d117ae31f458f8368ad7e7fa3fdb8",
            "d18b608945ec49ad84c7a46884358c59",
            "06e53ae2ce1c47eab5651c7b679540bf",
            "3cf04754bd1b462f9e3f37c3df7d28f2",
            "1623ba87908a4eb1955123abbeac30fd",
            "4beb992cee804851a67fe3d91c97b158",
            "4d3296e5bb8442f7a6adcc2bb32f3475",
            "31b4dda17a8b4159b7391a7b68e4561d",
            "ee305eda95b644bd8693d0c1bc4a4baa",
            "33a1ce88bae04d2a9bc46140cde6cda3",
            "7f110017992f4525b0208e7f3186b28e",
            "95f906b43418467cacb36d98059abf0f",
            "9b98a93bd7bd4d4e9af4b4a5b1c837bc",
            "bd66e890ae194357ae1b97d52f5199ec",
            "7ccbd946b1384c61ba25dded809951c1",
            "4e01034b93c14300bf7993a6e2f8674d",
            "e1b415cd8fa04a8eb819ad4999fd33ad",
            "0da526ab33a342f1b7846b03ec3b7cce",
            "de295de223104f299d3d61a0e408d85a",
            "0175e6fdf2824a0f860779d84f62d679",
            "d252e525705148e99097a946affe8c5d",
            "f7a1b95177f14c21b34f51e10a4dfb32",
            "ca8132cb3e9d4f8ca87e5da521a91002",
            "f7838c7e777748a88e4b38ebed2d7a6a",
            "84203bad8eb945408d2ae65b4f867085",
            "4273bd21768043018ba0bccbe7ed8798",
            "ec4f8a99c8a348edbe0bf4adfcf7df42",
            "bc07486285cd435e99f2d935a199b05a",
            "e35f81cf6c7d491abc4ece8176328963",
            "0a3a66da32314990a334f2d01f3aafb1",
            "6cb6f284c12941b6ba4d0f0af53de891",
            "d5d545f7d3ef465788ad463c7e901d43",
            "dee55fd2743345e5b76ee6ba9dcc1b85",
            "1b57785adafc423fbc22cb1d1b97d891",
            "f3f66cee55854c4694b585b0e3ab7883",
            "8f0a4c664b6743e080edeadf79e2d84a",
            "aba6992fc00b4877bed06c37b4464b26",
            "700b42d897784fbc82b638d494253ce3",
            "d3d6a48322824aa28313afb4cfc5250b",
            "9b9dc9d7fdf0490d9d65cfef3af5199a",
            "ce01e1856bec4afea94a3347d0a786f9",
            "c802d1d3cca2403687641e5f1fbb8800",
            "c772fdb2914a4e4bbf2f6b2dc3ae0edb",
            "14aff53c6935416480727fde1a45bf53",
            "29ddf9391ef34df39a443e9ccd2d9232",
            "ccfb93f1a02e4dfd8eb2b15a9a86ab68",
            "4af0db96d14d4b60a535a2c9f022dd46",
            "509602f9d950415eb44a7ed5eaf99742",
            "80c5d5ac17b54c8b89f7c349690c0b5c",
            "9be95bbf97ba4076afc9f32caf669b9e",
            "ecefc2126bc147a590a93a3d277f705c",
            "f68219592b1249f6b25a88ad691247d9",
            "be8be8e8cd2d43b3a0d718461c5ae71e",
            "7c5a8e406d924ce3bf7fe7ccb5587523"
          ]
        },
        "id": "NoKmMUG83egQ",
        "outputId": "d008d543-dbdc-40c9-86a7-dee41680dc18"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a53cc0581da949b19ccea2d9d8c9edca",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "501208bb8afc4150a5dad8ce74f56eb5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b05dfefdde1b4a11a182ae3234819578",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7f110017992f4525b0208e7f3186b28e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7a1b95177f14c21b34f51e10a4dfb32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dee55fd2743345e5b76ee6ba9dcc1b85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/3.13G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14aff53c6935416480727fde1a45bf53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "model_id = \"google/flan-t5-large\"\n",
        "t5_tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "t5_model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
        "\n",
        "qa_pipeline = pipeline(\"text2text-generation\", model=t5_model, tokenizer=t5_tokenizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xPtvk42tvjt-"
      },
      "source": [
        "# Generating the Final Answer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQiKEKw7s5We"
      },
      "source": [
        "Generates a well-structured answer using the retrieved context and question.  \n",
        "Truncates long input to stay within model limits and sends a clear prompt to the model.  \n",
        "Uses sampling (`temperature=0.7`, `top_p=0.9`) for more natural, varied responses.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ZB824Ad7ywX"
      },
      "outputs": [],
      "source": [
        "def generate_answer(question, retrieved_text, max_input_chars=1000):\n",
        "    # Truncate retrieved text to avoid overloading model\n",
        "    retrieved_text = retrieved_text[:max_input_chars]\n",
        "\n",
        "    prompt = f\"Give a concise, professional, complete and clear answer this question using the following data:\\n{retrieved_text}\\n\\nQuestion: {question}\"\n",
        "    print(\"----- Prompt Sent to Model -----\")\n",
        "    print(prompt)\n",
        "    print(\"--------------------------------\")\n",
        "\n",
        "    result = qa_pipeline(prompt, max_length=256, temperature=0.7, top_p=0.9, do_sample=True)\n",
        "\n",
        "\n",
        "    if result and 'generated_text' in result[0]:\n",
        "        return result[0]['generated_text']\n",
        "    else:\n",
        "        return \"[No answer returned from the model]\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9n6yj6gvnsm"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35lTxSCpvq4p"
      },
      "source": [
        "For the evaluation 5 questions were given to the model. Also Rouge-L score was used as a metric to one of the questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPAJVp0N4gAO",
        "outputId": "d5ca9f41-1d27-406e-b3bc-4a01e6afc44b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Prompt Sent to Model -----\n",
            "Give a concise, professional, complete and clear answer this question using the following data:\n",
            "that have been stored. From there the user can add items by selecting the + at the bottom of the screen, edit existing items by selecting the yellow pencil to the right of the stored item or delete them by selecting the red X to the right of the stored item. How to add an item? In the screen \"ADD ITEM\" the name and description of the item is filled in. Then select the department to which the article will fall, the gross sales price and the net profit. The net sales price is automatically filled in based on the\n",
            "---\n",
            "the desired quantity. Then select the X ,enter the price of the product and select the corresponding section. To import an item, you select \"ITEMS\" to display the items stored in the warehouse (See STORAGE section). After selecting the item, you press check. To enter a discount after the products have been entered, you select \"DISCOUNT\" and enter the discount value. To enter a comment, you select \"2nd level\" and then comment. You enter the comment and press check. The \"AC\" bu\n",
            "\n",
            "Question: How to add an item;\n",
            "--------------------------------\n",
            "----- Generated Answer -----\n",
            "In the screen \"ADD ITEM\" the name and description of the item is filled in. Then select the department to which the article will fall, the gross sales price and the net profit. The net sales price is automatically filled in based on the -- the desired quantity. Then select the X ,enter the price of the product and select the corresponding section.\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "question = \"How to add an item;\"\n",
        "retrieved = retrieve_answer(question)\n",
        "answer = generate_answer(question, retrieved)\n",
        "\n",
        "print(\"----- Generated Answer -----\")\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn8bIIr_YmbU",
        "outputId": "206a6309-a74f-47b6-c706-1efd05fa6bbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Prompt Sent to Model -----\n",
            "Give a concise, professional, complete and clear answer this question using the following data:\n",
            "within the network or save it to PDF. By clicking on the copies option the user can manage the print settings. He then selects the print icon to proceed to print the report. In the \"DAILY REPORT\" option the user selects the \"CREATE\" button to print the report giving data by category and totals. OPTIONS How to manage general parameters and connect the eft-pos? Through the \"General Parameters\" field, the declaration is made with the bank's application for card payments. In the menu you have to select the bank, select the check \"1155\", if it is the specific type of\n",
            "---\n",
            "bank's application for card payments. In the menu you have to select the bank, select the check \"1155\", if it is the specific type of connection, and fill in the TID that you will find in the bank's application. When it is a Worldline application, the user goes to the option \"Bank POS Management\" then to \"Connect to Worldline\" and fills in the details. The other fields in this menu are not related to the interface. Through \n",
            "\n",
            "Question: Can I connect EFT-POS;\n",
            "--------------------------------\n",
            "----- Generated Answer -----\n",
            "Yes\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "question = \"Can I connect EFT-POS;\"\n",
        "retrieved = retrieve_answer(question)\n",
        "answer = generate_answer(question, retrieved)\n",
        "\n",
        "print(\"----- Generated Answer -----\")\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSEgHX_vYtqD",
        "outputId": "a2f9597f-949d-40d0-f696-3593654030ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Prompt Sent to Model -----\n",
            "Give a concise, professional, complete and clear answer this question using the following data:\n",
            "within the network or save it to PDF. By clicking on the copies option the user can manage the print settings. He then selects the print icon to proceed to print the report. In the \"DAILY REPORT\" option the user selects the \"CREATE\" button to print the report giving data by category and totals. OPTIONS How to manage general parameters and connect the eft-pos? Through the \"General Parameters\" field, the declaration is made with the bank's application for card payments. In the menu you have to select the bank, select the check \"1155\", if it is the specific type of\n",
            "---\n",
            "bank's application for card payments. In the menu you have to select the bank, select the check \"1155\", if it is the specific type of connection, and fill in the TID that you will find in the bank's application. When it is a Worldline application, the user goes to the option \"Bank POS Management\" then to \"Connect to Worldline\" and fills in the details. The other fields in this menu are not related to the interface. Through \n",
            "\n",
            "Question: How to connect EFT-POS;\n",
            "--------------------------------\n",
            "----- Generated Answer -----\n",
            "Through the \"General Parameters\" field, the declaration is made with the bank's application for card payments. In the menu you have to select the bank, select the check \"1155\", if it is the specific type of connection, and fill in the TID that you will find in the bank's application.\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "question = \"How to connect EFT-POS;\"\n",
        "retrieved = retrieve_answer(question)\n",
        "answer = generate_answer(question, retrieved)\n",
        "\n",
        "print(\"----- Generated Answer -----\")\n",
        "print(answer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_L3Ba91nZDv8",
        "outputId": "66b26ca5-e2fa-4560-b07b-beec4c88a684"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Prompt Sent to Model -----\n",
            "Give a concise, professional, complete and clear answer this question using the following data:\n",
            "interface. Through the document selection field, the document that will be the default when starting the application for invoice issuance is selected. In the field \"Code In the field \"Prefix. Message\" field, the user fills in the code for sending a message during the issuance of a B2G document. When the user completes the selections then presses the green check to save. How to search with VAT number? In this option, the user fills in the name and password that the accountant will give him/her to find the customer details with the VAT number. When the user completes the options\n",
            "---\n",
            "the name and password that the accountant will give him/her to find the customer details with the VAT number. When the user completes the options then he/she clicks on the green check to save. How to connect to a Provider? In this option, the user declares the data that is linked (API KEY). In the \"Branch\" field, the user enters the digit indicating the corresponding branch. The digit for branch office is 0. \n",
            "\n",
            "Question: what is the topic of this manual?\n",
            "--------------------------------\n",
            "----- Generated Answer -----\n",
            "invoice issuance\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "question = \"what is the topic of this manual?\"\n",
        "retrieved = retrieve_answer(question)\n",
        "answer = generate_answer(question, retrieved)\n",
        "\n",
        "print(\"----- Generated Answer -----\")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJbyd8u4D9zP",
        "outputId": "cf93fea3-708c-4289-9861-8e6d83edc475"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Prompt Sent to Model -----\n",
            "Give a concise, professional, complete and clear answer this question using the following data:\n",
            "the desired quantity. Then select the X ,enter the price of the product and select the corresponding section. To import an item, you select \"ITEMS\" to display the items stored in the warehouse (See STORAGE section). After selecting the item, you press check. To enter a discount after the products have been entered, you select \"DISCOUNT\" and enter the discount value. To enter a comment, you select \"2nd level\" and then comment. You enter the comment and press check. The \"AC\" button is used to delete all the products that have been entered and the \"C\" button is used to\n",
            "---\n",
            "to be created, then click next to proceed to the next page. How to change contract details? You will then go to the contract details tab. If there is no registered contract then the mandatory fields (those with an asterisk) will need to be entered and the \"Budget\" option will be selected. Clicking OK will display the message \"Contract has been successfully added\". If the contract already exists then the contract details\n",
            "\n",
            "Question: How to enter a comment?\n",
            "--------------------------------\n",
            "----- Generated Answer -----\n",
            "Select \"2nd level\" and then comment. You enter the comment and press check.\n"
          ]
        }
      ],
      "source": [
        "# Example usage\n",
        "question = \"How to enter a comment?\"\n",
        "retrieved = retrieve_answer(question)\n",
        "answer = generate_answer(question, retrieved)\n",
        "\n",
        "print(\"----- Generated Answer -----\")\n",
        "print(answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCyAn-N7aV_1"
      },
      "outputs": [],
      "source": [
        "from rouge_score import rouge_scorer\n",
        "\n",
        "scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFQMPbLlaZDl"
      },
      "outputs": [],
      "source": [
        "evaluation_set = [\n",
        "    {\n",
        "        \"question\": \"How to connect EFT-POS?\",\n",
        "        \"expected_answer\": \"\"\"Through the General Parameters field, the declaration is made with the bank's application for card payments. In the menu you have to select the bank, select the check 1155, if it is the specific type of connection, and fill in the TID that you will find in the bank's application. When it is a Worldline application, the user goes to the option \"Bank POS Management\" then to \"Connect to Worldline\" and fills in the details. The other fields in this menu are not related to the interface.\"\"\"\n",
        "    }\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpzZGd2onxoA",
        "outputId": "a5d2b382-ab78-4550-9d59-0d4dd0084ca0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----- Prompt Sent to Model -----\n",
            "Give a concise, professional, complete and clear answer this question using the following data:\n",
            "within the network or save it to PDF. By clicking on the copies option the user can manage the print settings. He then selects the print icon to proceed to print the report. In the \"DAILY REPORT\" option the user selects the \"CREATE\" button to print the report giving data by category and totals. OPTIONS How to manage general parameters and connect the eft-pos? Through the \"General Parameters\" field, the declaration is made with the bank's application for card payments. In the menu you have to select the bank, select the check \"1155\", if it is the specific type of\n",
            "---\n",
            "bank's application for card payments. In the menu you have to select the bank, select the check \"1155\", if it is the specific type of connection, and fill in the TID that you will find in the bank's application. When it is a Worldline application, the user goes to the option \"Bank POS Management\" then to \"Connect to Worldline\" and fills in the details. The other fields in this menu are not related to the interface. Through \n",
            "\n",
            "Question: How to connect EFT-POS?\n",
            "--------------------------------\n",
            "Question: How to connect EFT-POS?\n",
            "ROUGE-L Score: 0.7376\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for item in evaluation_set:\n",
        "    retrieved = retrieve_answer(item[\"question\"])\n",
        "    generated = generate_answer(item[\"question\"], retrieved)\n",
        "    scores = scorer.score(item[\"expected_answer\"], generated)\n",
        "    print(f\"Question: {item['question']}\")\n",
        "    print(f\"ROUGE-L Score: {scores['rougeL'].fmeasure:.4f}\")\n",
        "    print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwNSuWGHudhN"
      },
      "source": [
        "# Conclusion\n",
        "\n",
        "This mini RAG system successfully answered five real questions based on the custom POS manual, showing how language models can support practical, domain-specific tasks. With a ROUGE-L score of **0.7376** on one of the questions, the responses were accurate and relevant. It’s a lightweight but powerful demo of how you can build smart assistants for specialized content.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}